{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04.Spark_Streaming_Kafka_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9d0x1OTh2N"
      },
      "source": [
        "# Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_DQBVj_KNvL"
      },
      "source": [
        "Installing Spark and Apache Kafka Library in VM\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGSM3_NM-z"
      },
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP_HtvSAj4sI"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:0.8.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog pyspark-shell'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGntFbiYNzUm"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fR7EuPOaN0JF",
        "outputId": "448348c8-67ec-47ee-97cd-92a84dca4f60"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.ui.port\", \"4050\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.2'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISbQw2DN1jO"
      },
      "source": [
        "Creating ngrok tunnel to allow Spark UI (Optional)\n",
        "**Only 20 connections/minute!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-7fXZiGmqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79ca208-7b81-4f23-984e-d16ea1fdb9e9"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-15 14:26:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 18.205.222.128, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  44.5MB/s    in 0.3s    \n",
            "\n",
            "2021-10-15 14:26:29 (44.5 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "https://5c10-35-231-5-119.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPVTLyFgrCJZ"
      },
      "source": [
        "# Structured Streaming with Apache Kafka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42PI1onm9kIh"
      },
      "source": [
        "## Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbf8iJP0AlkN"
      },
      "source": [
        "Reading a Kafka topic in AWS.\n",
        "Before executing this code, replace `kafka:9092` by the right bootstrap server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUIqs27uAvM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e32663d-303d-4a7f-8b39-e875012f354a"
      },
      "source": [
        "from pyspark.sql.functions import from_json, col\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "df = spark \\\n",
        "  .readStream \\\n",
        "  .format(\"kafka\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"ec2-3-91-30-167.compute-1.amazonaws.com:9092\") \\\n",
        "  .option(\"subscribe\", \"twitter\") \\\n",
        "  .load()\n",
        "  \n",
        "schema = StructType(\n",
        "    [\n",
        "        StructField('id', StringType(), True),\n",
        "        StructField('timestamp_ms', StringType(), True),\n",
        "        StructField('user', StringType(), True),\n",
        "        StructField('geo', StringType(), True),\n",
        "        StructField('play', StringType(), True),\n",
        "        StructField('text', StringType(), True)\n",
        "    ]\n",
        ")\n",
        "df.printSchema()\n",
        "\n",
        "dataset = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
        "    .withColumn(\"value\", from_json(\"value\", schema)) \\\n",
        "    .select(col('key'), col(\"timestamp\"), col('value.*'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- key: binary (nullable = true)\n",
            " |-- value: binary (nullable = true)\n",
            " |-- topic: string (nullable = true)\n",
            " |-- partition: integer (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- timestampType: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFE9-1mVb0oL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37eb6fd2-390c-420d-d02b-dbc5c7bb4a5b"
      },
      "source": [
        "dataset.writeStream \\\n",
        " .outputMode(\"append\") \\\n",
        " .format(\"memory\") \\\n",
        " .option(\"truncate\", \"false\") \\\n",
        " .queryName(\"tweets_topic\") \\\n",
        " .start()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.StreamingQuery at 0x7fa9dea588d0>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeYb_B40b4Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b295e7d-0bcd-4d15-c70e-2783210c16b6"
      },
      "source": [
        "spark.sql(\"select id, text from tweets_topic\").show(10, False)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id                 |text                                                                                                                                        |\n",
            "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1449028372730941444|RT @realLizUSA: The Pima County Fish Tail \n",
            "\n",
            "President Trump outperformed Republicans 3% on mail-in ballots\n",
            "\n",
            "Biden underperformed Democrats… |\n",
            "|1449028372995063809|@mistymeadow22 @ConservativeMMT @POTUS There are always two sides to a story. I can explain accurately and fairly w… https://t.co/sCb1nvJBL9|\n",
            "|1449028375151054852|RT @jonathanalter: At least 97 percent of other nations prefer Biden and Blinken to Trump and Pompeo. Russia, Hungary and one or two others…|\n",
            "|1449028374618378241|RT @sarahkendzior: These rumors about Trump's sexual proclivities are so unfair. We all know that what he's into is rape and befriending mu…|\n",
            "|1449028374102515716|RT @tifffuxxsake: The only thing that surprises me about Trump’s “I’m not into golden showers”, is that he didn’t say it in a room full of… |\n",
            "|1449028374161199133|The only irregularity - this was country wide\n",
            "the country is full of anti Trump\n",
            "take your medicine\n",
            "Trump got the va… https://t.co/TWB2fekZx8|\n",
            "|1449028375625011230|I. Thought. We. Agreed. This. Was a. Non. Starter. As. It. Meant. Thousands. Would. Be. Murdered. Begging. For. Our… https://t.co/uXuf6MiCDX|\n",
            "|1449028373863440384|RT @richsignorelli: DNA has been recovered from @ejeancarroll's credibly alleged rape by Trump. If Trump supposedly doesn't know her, why w…|\n",
            "|1449028376371490817|RT @StrictlyChristo: 'Trump Lost' billboard in Times Square, paid for by Republicans https://t.co/UzUYcSepIF                                |\n",
            "|1449028375234760708|RT @letsgomathias: \"That Mault could rejoin the Army ― when he was listed as suspect no. 142 on the FBI’s Capitol Violence wanted list ― ra…|\n",
            "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkR3V9kYE6IF"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmTOOQQUE8KV"
      },
      "source": [
        "Apply a sliding window each minute, 5 minutes of duration, grouping by id\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnHdFUvEESoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab4da12-dd37-4a33-8913-b81f3d209711"
      },
      "source": [
        "from pyspark.sql.functions import col, window\n",
        "\n",
        "dataset.groupBy(window(col(\"timestamp\"), \"5 minutes\", \"1 minutes\"), col(\"id\")) \\\n",
        "    .count() \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"tweets_windowed\") \\\n",
        "    .start()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.StreamingQuery at 0x7fa9ded77390>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg1lH6HwFhc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d2ebab-1543-47a7-ad3d-eed07cad8e5d"
      },
      "source": [
        "spark.sql(\"select * from tweets_windowed order by count desc\").show(20, False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+-------------------+-----+\n",
            "|window                                    |id                 |count|\n",
            "+------------------------------------------+-------------------+-----+\n",
            "|{2021-10-15 14:51:00, 2021-10-15 14:56:00}|1449025109306511366|1    |\n",
            "|{2021-10-15 14:50:00, 2021-10-15 14:55:00}|1449025363665948696|1    |\n",
            "|{2021-10-15 14:50:00, 2021-10-15 14:55:00}|1449025405080457217|1    |\n",
            "|{2021-10-15 14:56:00, 2021-10-15 15:01:00}|1449026373163573251|1    |\n",
            "|{2021-10-15 14:50:00, 2021-10-15 14:55:00}|1449025459749064737|1    |\n",
            "|{2021-10-15 14:51:00, 2021-10-15 14:56:00}|1449025255473877029|1    |\n",
            "|{2021-10-15 14:48:00, 2021-10-15 14:53:00}|1449025234284253212|1    |\n",
            "|{2021-10-15 14:55:00, 2021-10-15 15:00:00}|1449026317987430401|1    |\n",
            "|{2021-10-15 14:52:00, 2021-10-15 14:57:00}|1449025873449865224|1    |\n",
            "|{2021-10-15 14:52:00, 2021-10-15 14:57:00}|1449026348475944994|1    |\n",
            "|{2021-10-15 14:47:00, 2021-10-15 14:52:00}|1449025175647883289|1    |\n",
            "|{2021-10-15 14:50:00, 2021-10-15 14:55:00}|1449025214176759830|1    |\n",
            "|{2021-10-15 14:54:00, 2021-10-15 14:59:00}|1449025832064847873|1    |\n",
            "|{2021-10-15 14:52:00, 2021-10-15 14:57:00}|1449026192808546357|1    |\n",
            "|{2021-10-15 14:51:00, 2021-10-15 14:56:00}|1449025968975138822|1    |\n",
            "|{2021-10-15 14:49:00, 2021-10-15 14:54:00}|1449025136313528328|1    |\n",
            "|{2021-10-15 14:49:00, 2021-10-15 14:54:00}|1449025152503717888|1    |\n",
            "|{2021-10-15 14:51:00, 2021-10-15 14:56:00}|1449025346863448070|1    |\n",
            "|{2021-10-15 14:53:00, 2021-10-15 14:58:00}|1449025690087661568|1    |\n",
            "|{2021-10-15 14:52:00, 2021-10-15 14:57:00}|1449025938289725448|1    |\n",
            "+------------------------------------------+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W5pcAqFdk0h"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDW6jxpsdoGI"
      },
      "source": [
        "Each minute, get the number of tweets received in last 5 minutes\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbUjICTnIeOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad31c71-33f9-4707-e223-618b5ac0efa3"
      },
      "source": [
        "dataset.groupBy(window(col(\"timestamp\"), \"5 minutes\", \"1 minutes\")) \\\n",
        "    .count() \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"tweets_windowed_2\") \\\n",
        "    .start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.StreamingQuery at 0x7fad81f6b630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXkT71fLd_SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7ec9a7-1854-47ba-93b3-b6eecbcc3336"
      },
      "source": [
        "spark.sql(\"select * from tweets_windowed_2 order by count desc\").show(50, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------+-----+\n",
            "|window                                    |count|\n",
            "+------------------------------------------+-----+\n",
            "|[2021-02-18 08:22:00, 2021-02-18 08:27:00]|166  |\n",
            "|[2021-02-18 08:25:00, 2021-02-18 08:30:00]|166  |\n",
            "|[2021-02-18 08:23:00, 2021-02-18 08:28:00]|166  |\n",
            "|[2021-02-18 08:24:00, 2021-02-18 08:29:00]|166  |\n",
            "|[2021-02-18 08:21:00, 2021-02-18 08:26:00]|138  |\n",
            "|[2021-02-18 08:26:00, 2021-02-18 08:31:00]|28   |\n",
            "|[2021-02-18 08:22:00, 2021-02-18 08:27:00]|3    |\n",
            "|[2021-02-18 08:23:00, 2021-02-18 08:28:00]|3    |\n",
            "|[2021-02-18 08:24:00, 2021-02-18 08:29:00]|3    |\n",
            "|[2021-02-18 08:25:00, 2021-02-18 08:30:00]|3    |\n",
            "|[2021-02-18 08:21:00, 2021-02-18 08:26:00]|3    |\n",
            "+------------------------------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxJyQip9exxX"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wbL-LCuezVu"
      },
      "source": [
        "Get tweets containing the word `Trump` in 1 minute slots\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQbOueaAeDX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6a985c-77b4-427c-fb0e-afd988b8681a"
      },
      "source": [
        "from pyspark.sql.functions import lower\n",
        "\n",
        "dataset = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
        "    .withColumn(\"value\", from_json(\"value\", schema)) \\\n",
        "    .select(col('key'), col(\"timestamp\"), col('value.*')) \\\n",
        "    .filter(lower(col('text')).contains(\"Biden\"))\n",
        "\n",
        "dataset.groupBy(window(col(\"timestamp\"), \"1 minutes\")) \\\n",
        "    .count() \\\n",
        "    .writeStream \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"tweets_windowed_biden\") \\\n",
        "    .start()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.streaming.StreamingQuery at 0x7fa9de9eab90>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJLAZ2UffEPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a75f05-196a-410a-d462-e328b4bac480"
      },
      "source": [
        "spark.sql(\"select * from tweets_windowed_biden\").show(10, False)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|window|count|\n",
            "+------+-----+\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOtxXD9YfWA8"
      },
      "source": [
        "for query in spark.streams.active:\n",
        "  query.stop()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXsww3CwdnEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}