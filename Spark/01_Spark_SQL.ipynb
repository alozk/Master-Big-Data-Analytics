{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01.Spark_SQL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jq9d0x1OTh2N",
        "8Z0h3dF9Vg4X"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9d0x1OTh2N"
      },
      "source": [
        "# Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_DQBVj_KNvL"
      },
      "source": [
        "Installing Spark\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGSM3_NM-z"
      },
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooP8hZlothY4"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LqjbMdHw4CV"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdFv-xxITa2J"
      },
      "source": [
        "Starting Spark Session and print the version\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDLMbVBATf9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edae19d5-2a6c-444b-f619-3b0b9e12dab8"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNiYuI5dGo8Y"
      },
      "source": [
        "Creating tunnel</br>\n",
        "**To Check the Spark UI, open the URL printed by running the above command : https://######/jobs/, /SQL/**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-7fXZiGmqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "800526d8-93dc-428e-d69e-6373dce9c4d8"
      },
      "source": [
        " from google.colab.output import eval_js\n",
        " print(eval_js(\"google.colab.kernel.proxyPort(4040)\") + \"jobs/\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://685dkryomar-496ff2e9c6d22116-4040-colab.googleusercontent.com/jobs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z0h3dF9Vg4X"
      },
      "source": [
        "# Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBDin-0sXgyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23264ee-f392-43b3-f20c-f73b5340b603"
      },
      "source": [
        "!mkdir -p /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/netflix_titles.csv -P /dataset\n",
        "!ls /dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank.csv    characters.csv    netflix_titles.csv    vehicles.csv\n",
            "bank.csv.1  characters.csv.1  netflix_titles.csv.1  vehicles.csv.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Zwm3NRXS_I"
      },
      "source": [
        "# Reading Data with Spark SQL\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o6f6QOjTcZ"
      },
      "source": [
        "## Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USrsDETtstv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bef31f4-5a90-484b-f01b-82f6cee3baca"
      },
      "source": [
        "!head /dataset/bank.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
            "30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"\n",
            "33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"\n",
            "35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"\n",
            "30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"\n",
            "59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"\n",
            "35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failure\";\"no\"\n",
            "36;\"self-employed\";\"married\";\"tertiary\";\"no\";307;\"yes\";\"no\";\"cellular\";14;\"may\";341;1;330;2;\"other\";\"no\"\n",
            "39;\"technician\";\"married\";\"secondary\";\"no\";147;\"yes\";\"no\";\"cellular\";6;\"may\";151;2;-1;0;\"unknown\";\"no\"\n",
            "41;\"entrepreneur\";\"married\";\"tertiary\";\"no\";221;\"yes\";\"no\";\"unknown\";14;\"may\";57;2;-1;0;\"unknown\";\"no\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjPpxRyJYA1h"
      },
      "source": [
        "Converting a RDD to a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnbafeFCVk8d"
      },
      "source": [
        "from pyspark.sql.types import Row\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "bankText = spark.sparkContext.textFile(\"/dataset/bank.csv\")\n",
        "\n",
        "bank = bankText.map(lambda lineaCsv: lineaCsv.split(\";\"))\\\n",
        ".filter(lambda s: s[0] != \"\\\"age\\\"\") \\\n",
        ".map(lambda row: Row(int(row[0]), row[1].replace(\"\\\"\", \"\"), row[2].replace(\"\\\"\", \"\"), row[3].replace(\"\\\"\", \"\"), row[5].replace(\"\\\"\", \"\"))) \\\n",
        ".toDF([\"age\", \"job\", \"marital\", \"education\", \"balance\"]) \\\n",
        ".withColumn(\"age\", col(\"age\").cast(\"int\"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BEWmhhYqxp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610cafdb-f096-4c1b-d328-d929ccfeb878"
      },
      "source": [
        "bank.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- balance: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7kQm1A5q00M"
      },
      "source": [
        "bank.createOrReplaceTempView(\"bank\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM Bank\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwPqjT0edxaz",
        "outputId": "2b3fba23-ad63-4cd6-817b-85065197347c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+---------+-------+\n",
            "|age|          job|marital|education|balance|\n",
            "+---+-------------+-------+---------+-------+\n",
            "| 30|   unemployed|married|  primary|   1787|\n",
            "| 33|     services|married|secondary|   4789|\n",
            "| 35|   management| single| tertiary|   1350|\n",
            "| 30|   management|married| tertiary|   1476|\n",
            "| 59|  blue-collar|married|secondary|      0|\n",
            "| 35|   management| single| tertiary|    747|\n",
            "| 36|self-employed|married| tertiary|    307|\n",
            "| 39|   technician|married|secondary|    147|\n",
            "| 41| entrepreneur|married| tertiary|    221|\n",
            "| 43|     services|married|  primary|    -88|\n",
            "| 39|     services|married|secondary|   9374|\n",
            "| 43|       admin.|married|secondary|    264|\n",
            "| 36|   technician|married| tertiary|   1109|\n",
            "| 20|      student| single|secondary|    502|\n",
            "| 31|  blue-collar|married|secondary|    360|\n",
            "| 40|   management|married| tertiary|    194|\n",
            "| 56|   technician|married|secondary|   4073|\n",
            "| 37|       admin.| single| tertiary|   2317|\n",
            "| 25|  blue-collar| single|  primary|   -221|\n",
            "| 31|     services|married|secondary|    132|\n",
            "+---+-------------+-------+---------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-JI8uCsroG7"
      },
      "source": [
        "Loading a **Google Colab extension** to show a table with filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCGzK_zfrm8u"
      },
      "source": [
        "%load_ext google.colab.data_table"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE6JMclKbbkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcc671d-545b-433c-cb93-a762f3f86957"
      },
      "source": [
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "bank_grouped = bank\\\n",
        ".groupBy(bank.marital) \\\n",
        ".agg({\"balance\": \"avg\"}) \\\n",
        ".select(\"marital\", col(\"avg(balance)\").alias(\"balance_avg\")) \\\n",
        ".orderBy(col(\"balance_avg\").desc())\\\n",
        "\n",
        "bank_grouped.show()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "| marital|       balance_avg|\n",
            "+--------+------------------+\n",
            "| married| 1463.195566678584|\n",
            "|  single|1460.4147157190635|\n",
            "|divorced|1122.3901515151515|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ1vduJ45VtS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "548a948c-c3d5-41ef-ec45-b682e510fb06"
      },
      "source": [
        "bank_grouped.toPandas()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"married\",\n{\n            'v': 1463.195566678584,\n            'f': \"1463.195566678584\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"single\",\n{\n            'v': 1460.4147157190635,\n            'f': \"1460.4147157190635\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"divorced\",\n{\n            'v': 1122.3901515151515,\n            'f': \"1122.3901515151515\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"marital\"], [\"number\", \"balance_avg\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "\n",
              "  <div id=\"df-f9af58c2-07ff-4352-9a8b-aa384b108c39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marital</th>\n",
              "      <th>balance_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>married</td>\n",
              "      <td>1463.195567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>single</td>\n",
              "      <td>1460.414716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>divorced</td>\n",
              "      <td>1122.390152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9af58c2-07ff-4352-9a8b-aa384b108c39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9af58c2-07ff-4352-9a8b-aa384b108c39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9af58c2-07ff-4352-9a8b-aa384b108c39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    marital  balance_avg\n",
              "0   married  1463.195567\n",
              "1    single  1460.414716\n",
              "2  divorced  1122.390152"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTy8ySNSpgpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5bdc3b-14f9-4f26-fe62-f44a0a161e8c"
      },
      "source": [
        "spark.sql(\"SELECT marital, avg(balance) as balance_avg FROM bank group by marital\").show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "| marital|       balance_avg|\n",
            "+--------+------------------+\n",
            "|divorced|1122.3901515151515|\n",
            "| married| 1463.195566678584|\n",
            "|  single|1460.4147157190635|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CJgXJe-kpnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "bc1b63fb-37bd-4eba-a2e5-7f3ef80d0abf"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.pie(bank_grouped.toPandas(), values='balance_avg', names='marital', title='By Marital')\n",
        "fig.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"90075ebb-73cb-4477-a6af-c55ee553db80\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"90075ebb-73cb-4477-a6af-c55ee553db80\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '90075ebb-73cb-4477-a6af-c55ee553db80',\n",
              "                        [{\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"marital=%{label}<br>balance_avg=%{value}\", \"labels\": [\"married\", \"single\", \"divorced\"], \"legendgroup\": \"\", \"name\": \"\", \"showlegend\": true, \"type\": \"pie\", \"values\": [1463.195566678584, 1460.4147157190635, 1122.3901515151515]}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"By Marital\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('90075ebb-73cb-4477-a6af-c55ee553db80');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzU_4EjAjZgh"
      },
      "source": [
        "## Example 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV-NchsMsHvF"
      },
      "source": [
        "Loading a CSV file as RDD, converting into a DataFrame, applying a specific schema using the method `createDataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgireGq6YWEj"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "bankSchema = StructType([\n",
        "    StructField(\"age\", IntegerType(), False), \n",
        "    StructField(\"job\", StringType(), False),\n",
        "    StructField(\"marital\", StringType(), False),\n",
        "    StructField(\"education\", StringType(), False),\n",
        "    StructField(\"balance\", IntegerType(), False)])\n",
        "\n",
        "bankText = spark.sparkContext.textFile(\"/dataset/bank.csv\")\n",
        "\n",
        "bank = bankText\\\n",
        ".map(lambda s: s.split(\";\")).filter(lambda s: s[0] != \"\\\"age\\\"\")\\\n",
        ".map(lambda s:(int(s[0]), str(s[1]).replace(\"\\\"\", \"\"), str(s[2]).replace(\"\\\"\", \"\"), str(s[3]).replace(\"\\\"\", \"\"), int(s[5]) ))\n",
        "\n",
        "bankdf = spark.createDataFrame(bank, bankSchema)\n",
        "bankdf.createOrReplaceTempView(\"bank2\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTSxYSiqtwum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def24db5-bfdb-4f0a-f227-20054f7ff464"
      },
      "source": [
        "spark.sql(\"select * from bank2 limit 10\").show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+---------+-------+\n",
            "|age|          job|marital|education|balance|\n",
            "+---+-------------+-------+---------+-------+\n",
            "| 30|   unemployed|married|  primary|   1787|\n",
            "| 33|     services|married|secondary|   4789|\n",
            "| 35|   management| single| tertiary|   1350|\n",
            "| 30|   management|married| tertiary|   1476|\n",
            "| 59|  blue-collar|married|secondary|      0|\n",
            "| 35|   management| single| tertiary|    747|\n",
            "| 36|self-employed|married| tertiary|    307|\n",
            "| 39|   technician|married|secondary|    147|\n",
            "| 41| entrepreneur|married| tertiary|    221|\n",
            "| 43|     services|married|  primary|    -88|\n",
            "+---+-------------+-------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX0FXU7JawRm"
      },
      "source": [
        "## Exercise 1\n",
        "Load file `vehicles.csv` to a DataFrame, showing the content and printing the schema.\n",
        "\n",
        "Use this [documentation](https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html) to read data in a DataFrame\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCDfqm_UxUcn"
      },
      "source": [
        "Filter out the previous DafaFrame to get vehicles where the capicity is greater than 70\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IdhtILfwmSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db67af5a-2869-4944-cf03-e099bccf4fd4"
      },
      "source": [
        "!head /dataset/vehicles.csv"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name,model,manufacturer,cost_in_credits,length,max_atmosphering_speed,crew,passengers,cargo_capacity,consumables,vehicle_class\n",
            "Sand Crawler,Digger Crawler,Corellia Mining Corporation,150000,36.8,30,46,30,50000,2 months,wheeled\n",
            "T-16 skyhopper,T-16 skyhopper,Incom Corporation,14500,10.4,1200,1,1,50,0,repulsorcraft\n",
            "X-34 landspeeder,X-34 landspeeder,SoroSuub Corporation,10550,3.4,250,1,1,5,NA,repulsorcraft\n",
            "TIE/LN starfighter,Twin Ion Engine/Ln Starfighter,Sienar Fleet Systems,NA,6.4,1200,1,0,65,2 days,starfighter\n",
            "Snowspeeder,t-47 airspeeder,Incom corporation,NA,4.5,650,2,0,10,none,airspeeder\n",
            "TIE bomber,TIE/sa bomber,Sienar Fleet Systems,NA,7.8,850,1,0,none,2 days,space/planetary bomber\n",
            "AT-AT,All Terrain Armored Transport,\"Kuat Drive Yards, Imperial Department of Military Research\",NA,20,60,5,40,1000,NA,assault walker\n",
            "AT-ST,All Terrain Scout Transport,\"Kuat Drive Yards, Imperial Department of Military Research\",NA,2,90,2,0,200,none,walker\n",
            "Storm IV Twin-Pod cloud car,Storm IV Twin-Pod,Bespin Motors,75000,7,1500,2,0,10,1 day,repulsorcraft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vehiclesDF_all=spark.read.format('csv').option('sep',',').option('inferSchema', 'true').option('header', 'true').load('/dataset/vehicles.csv')"
      ],
      "metadata": {
        "id": "jw5Ix6ApcGol"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "cargo_cap=vehiclesDF_all.withColumn('cargo_capacity', col('cargo_capacity').cast('int'))\n",
        "cargo_cap.createOrReplaceTempView('cargo_cap') #hago que mi tabla exita en sql\n",
        "spark.sql('SELECT cargo_capacity FROM cargo_cap WHERE cargo_capacity >70').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaxuy6g3giOi",
        "outputId": "6d45c4d7-1e6a-46f3-b557-5b9d76a34be7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|cargo_capacity|\n",
            "+--------------+\n",
            "|         50000|\n",
            "|          1000|\n",
            "|           200|\n",
            "|       2000000|\n",
            "|        135000|\n",
            "|            75|\n",
            "|         12000|\n",
            "|       1800000|\n",
            "|          1600|\n",
            "|           200|\n",
            "|            80|\n",
            "|           170|\n",
            "|         40000|\n",
            "|         30000|\n",
            "|         10000|\n",
            "|           500|\n",
            "|          1000|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GUV9KLzqR-4"
      },
      "source": [
        "# Spark SQL. Aggregation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbMEyQFOqVnQ"
      },
      "source": [
        "Useful Links:\n",
        "\n",
        "http://spark.apache.org/docs/latest/api/python/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZw41ki6kc3p"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAzx5B5IkVeP"
      },
      "source": [
        "Using the DataFrame with all vehicles loaded in Exercise 1, get the number of passengers by vehicle class\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIKCDk4mx0ep"
      },
      "source": [
        "vehiclesDF_all = spark.read.format(\"csv\").option(\"sep\", \";\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"/dataset/vehicles.csv\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vehiclesDF_all.groupBy('vehicle_class').agg({'passengers':'avg'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "djh_vRnsjGeG",
        "outputId": "60067837-56af-480f-dda9-dc3466826044"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d71bff7b548d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvehiclesDF_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vehicle_class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'passengers'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exprs should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.0-bin-hadoop3.2/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1310\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"passengers\" among (name,model,manufacturer,cost_in_credits,length,max_atmosphering_speed,crew,passengers,cargo_capacity,consumables,vehicle_class)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEBVnVQlU52"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF4fyAaMlXsI"
      },
      "source": [
        "Load the file `characters.csv` getting the most common eye color among all characters\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ_HrY7uk3bM"
      },
      "source": [
        "charactersDF_all=spark.read.format('csv').option('sep',',').option('inferSchema', 'true').option('header', 'true').load('/dataset/characters.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "charactersDF_all.groupBy('eye_color').agg({'eye_color':'count'}).orderBy(desc('count(eye_color)')).limit(1).show()\n"
      ],
      "metadata": {
        "id": "wHHY2fqvltku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-AFIMvm43z"
      },
      "source": [
        "## Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9UBVU6ym9ue"
      },
      "source": [
        "1. Load characters DataFrame into a temporary table\n",
        "2. Using SQL, get the number of characters by gender\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "charactersDF_all=spark.read.format('csv').option('sep',',').option('inferSchema', 'true').option('header', 'true').load('/dataset/characters.csv')"
      ],
      "metadata": {
        "id": "lzOOAMRQtFiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdBgPJ8bnvsq"
      },
      "source": [
        "charactersDF_all.createOrReplaceTempView(\"characters_t\")\n",
        "\n",
        "sqlDF = spark.sql(\n",
        "    \"SELECT gender, count(distinct name) as number_of_characters \"\\\n",
        "    \"FROM characters_t group by gender order by number_of_characters desc\")\n",
        "sqlDF.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv0AmHi926F7"
      },
      "source": [
        "## Exercise 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR6FPU3b29TP"
      },
      "source": [
        "Load `netflix_titles.csv` file in a DataFrame, printing the schema\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zyuYbll3UrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea4b16a-7e8b-4c57-ac59-d386ce073614"
      },
      "source": [
        "!head /dataset/netflix_titles.csv"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "show_id,type,title,director,cast,country,date_added,release_year,rating,duration,listed_in,description\n",
            "81145628,Movie,Norm of the North: King Sized Adventure,\"Richard Finn, Tim Maltby\",\"Alan Marriott, Andrew Toth, Brian Dobson, Cole Howard, Jennifer Cameron, Jonathan Holmes, Lee Tockar, Lisa Durupt, Maya Kay, Michael Dobson\",\"United States, India, South Korea, China\",\"September 9, 2019\",2019,TV-PG,90 min,\"Children & Family Movies, Comedies\",\"Before planning an awesome wedding for his grandfather, a polar bear king must take back a stolen artifact from an evil archaeologist first.\"\n",
            "80117401,Movie,Jandino: Whatever it Takes,,Jandino Asporaat,United Kingdom,\"September 9, 2016\",2016,TV-MA,94 min,Stand-Up Comedy,\"Jandino Asporaat riffs on the challenges of raising kids and serenades the audience with a rousing rendition of \"\"Sex on Fire\"\" in his comedy show.\"\n",
            "70234439,TV Show,Transformers Prime,,\"Peter Cullen, Sumalee Montano, Frank Welker, Jeffrey Combs, Kevin Michael Richardson, Tania Gunadi, Josh Keaton, Steve Blum, Andy Pessoa, Ernie Hudson, Daran Norris, Will Friedle\",United States,\"September 8, 2018\",2013,TV-Y7-FV,1 Season,Kids' TV,\"With the help of three human allies, the Autobots once again protect Earth from the onslaught of the Decepticons and their leader, Megatron.\"\n",
            "80058654,TV Show,Transformers: Robots in Disguise,,\"Will Friedle, Darren Criss, Constance Zimmer, Khary Payton, Mitchell Whitfield, Stuart Allan, Ted McGinley, Peter Cullen\",United States,\"September 8, 2018\",2016,TV-Y7,1 Season,Kids' TV,\"When a prison ship crash unleashes hundreds of Decepticons on Earth, Bumblebee leads a new Autobot force to protect humankind.\"\n",
            "80125979,Movie,#realityhigh,Fernando Lebrija,\"Nesta Cooper, Kate Walsh, John Michael Higgins, Keith Powers, Alicia Sanz, Jake Borelli, Kid Ink, Yousef Erakat, Rebekah Graf, Anne Winters, Peter Gilroy, Patrick Davis\",United States,\"September 8, 2017\",2017,TV-14,99 min,Comedies,\"When nerdy high schooler Dani finally attracts the interest of her longtime crush, she lands in the cross hairs of his ex, a social media celebrity.\"\n",
            "80163890,TV Show,Apaches,,\"Alberto Ammann, Eloy Azorín, Verónica Echegui, Lucía Jiménez, Claudia Traisac\",Spain,\"September 8, 2017\",2016,TV-MA,1 Season,\"Crime TV Shows, International TV Shows, Spanish-Language TV Shows\",A young journalist is forced into a life of crime to save his father and family in this series based on the novel by Miguel Sáez Carral.\n",
            "70304989,Movie,Automata,Gabe Ibáñez,\"Antonio Banderas, Dylan McDermott, Melanie Griffith, Birgitte Hjort Sørensen, Robert Forster, Christa Campbell, Tim McInnerny, Andy Nyman, David Ryall\",\"Bulgaria, United States, Spain, Canada\",\"September 8, 2017\",2014,R,110 min,\"International Movies, Sci-Fi & Fantasy, Thrillers\",\"In a dystopian future, an insurance adjuster for a tech company investigates a robot killed for violating protocol and discovers a global conspiracy.\"\n",
            "80164077,Movie,Fabrizio Copano: Solo pienso en mi,\"Rodrigo Toro, Francisco Schultz\",Fabrizio Copano,Chile,\"September 8, 2017\",2017,TV-MA,60 min,Stand-Up Comedy,\"Fabrizio Copano takes audience participation to the next level in this stand-up set while reflecting on sperm banks, family WhatsApp groups and more.\"\n",
            "80117902,TV Show,Fire Chasers,,,United States,\"September 8, 2017\",2017,TV-MA,1 Season,\"Docuseries, Science & Nature TV\",\"As California's 2016 fire season rages, brave backcountry firefighters race to put out the flames, protect homes and save lives in this docuseries.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG81SgpY4P3t"
      },
      "source": [
        "## Exercise 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56fGSsmt4adO"
      },
      "source": [
        "Get the year in which most films were added(No TV Shows). Use a UDF to get the year\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "group by movie, date added and count top 1"
      ],
      "metadata": {
        "id": "aOfCK7mFs-UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_year = udf(lambda s: s[-4:])"
      ],
      "metadata": {
        "id": "TmKJJWNVzG_p"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflixDF_all=spark.read.format('csv').option('sep',',').option('inferSchema', 'true').option('header', 'true').load('/dataset/netflix_titles.csv')\\\n",
        ".filter('date_added is not null')\\\n",
        ".filter(\"type == 'Movie'\").\\\n",
        "select('date_added', get_year('date_added').alias('year')).\\\n",
        "groupby('year').count().\\\n",
        "orderBy(desc('count')).limit(1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRxLxhF11yU0",
        "outputId": "ba684176-9fcc-4785-98b9-80d4145e9ff2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|2019| 1545|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}